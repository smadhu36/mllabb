from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt
from sklearn.tree import export_graphviz
import graphviz

# Load breast cancer dataset
data = load_breast_cancer(as_frame=True)
X, y = data.data, data.target

# Print feature names
feature_names = X.columns.tolist()
print("Feature names:", feature_names)

# Separating Training and Testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)

# Train the original decision tree model
original_model = DecisionTreeClassifier(criterion="entropy")
original_model.fit(X_train, y_train)

# Model Accuracy before pruning
accuracy_before_pruning = original_model.score(X_test, y_test)
print("Accuracy before pruning:", accuracy_before_pruning)

# Plot original tree
plt.figure(figsize=(15, 10))
plot_tree(original_model, filled=True, feature_names=feature_names)
plt.title("Original Decision Tree")
plt.show()

# Cost-complexity pruning (Post-pruning)
path = original_model.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

# Train a series of decision trees with different alpha values
pruned_models = []
for ccp_alpha in ccp_alphas:
    pruned_model = DecisionTreeClassifier(criterion="entropy", ccp_alpha=ccp_alpha)
    pruned_model.fit(X_train, y_train)
    pruned_models.append(pruned_model)

# Find the model with the best accuracy on test data
best_accuracy = 0
best_pruned_model = None
for pruned_model in pruned_models:
    accuracy = pruned_model.score(X_test, y_test)
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_pruned_model = pruned_model

# Model Accuracy after pruning
accuracy_after_pruning = best_pruned_model.score(X_test, y_test)
print("Accuracy after pruning:", accuracy_after_pruning)

# Plot pruned tree with feature names
plt.figure(figsize=(15, 10))
plot_tree(best_pruned_model, filled=True, feature_names=feature_names)
plt.title("Pruned Decision Tree with Cost-Complexity Pruning")
plt.show()
